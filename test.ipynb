{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42b0c89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.open_deep_research.configuration import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd2e47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchAPI(Enum):\n",
    "    ANTHROPIC = \"anthropic\"\n",
    "    OPENAI = \"openai\"\n",
    "    TAVILY = \"tavily\"\n",
    "\n",
    "    NONE= \"none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e600ca26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCPConfig(BaseModel):\n",
    "    url: Optional[str] = Field(\n",
    "        default = None,\n",
    "        description=\"The URL of the MCP Server\"\n",
    "        )\n",
    "\n",
    "    tools: Optional[str] = Field(\n",
    "        default= False,\n",
    "        description=\"The tools to make available to the LLM\"\n",
    "    )\n",
    "\n",
    "    auth_required: Optional[bool] = Field(\n",
    "        default = False,\n",
    "        description = \"Whether the MCP server requires authentication\"\n",
    "    )\n",
    "\n",
    "\n",
    "class configuration(BaseModel):\n",
    "\n",
    "    max_structured_output_retries: int = Field(\n",
    "        default = 3,\n",
    "        metadata = {\n",
    "            \"x_oap_ui_config\": {\n",
    "                \"type\": \"number\",\n",
    "                \"default\" : 3,\n",
    "                \"min\": 1,\n",
    "                \"max\": 10,\n",
    "                \"description\" : \"Maximum number of retries for structured output calls from models\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    allow_clarification: bool = Field(\n",
    "        default = True, \n",
    "        metadata={\n",
    "            \"x_oap_ui_config\": {\n",
    "                \"type\": \"boolean\",\n",
    "                \"default\": True,\n",
    "                \"description\": \"Whether to allow the researcher to ask the user clarifying questions before starting research\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    max_concurrent_research_units: int = Field(\n",
    "        default = 5,\n",
    "        metadata = {\n",
    "            \"x_oap_ui_config\": {\n",
    "                \"type\": \"slider\",\n",
    "                \"default\": 5,\n",
    "                \"min\": 1,\n",
    "                \"max\": 20,\n",
    "                \"step\": 1,\n",
    "                \"description\": \"Maximum number of research units to run concurrently. This will allow the researcher to use multiple sub-agents to conduct research. Note: with more concurrency, you may run into rate limits\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Research Configuration\n",
    "    search_api: SearchAPI = Field(\n",
    "        default=SearchAPI.TAVILY,\n",
    "        metadata={\n",
    "            \"x_oap_ui_config\": {\n",
    "                \"type\": \"select\",\n",
    "                \"default\": \"tavily\",\n",
    "                \"description\": \"Search API to use for research. NOTE: Make sure your Researcher Model supports the selected search API.\",\n",
    "                \"options\": [\n",
    "                    {\"label\": \"Tavily\", \"value\": SearchAPI.TAVILY.value},\n",
    "                    {\"label\": \"OpenAI Native Web Search\", \"value\": SearchAPI.OPENAI.value},\n",
    "                    {\"label\": \"Anthropic Native Web Search\", \"value\": SearchAPI.ANTHROPIC.value},\n",
    "                    {\"label\": \"None\", \"value\": SearchAPI.NONE.value}\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    max_react_tool_calls: int = Field(\n",
    "        default = 5,\n",
    "        metadata={\n",
    "            \"x_oap_ui_config\": {\n",
    "                \"type\": \"slider\",\n",
    "                \"default\": 5,\n",
    "                \"min\": 1,\n",
    "                \"max\": 30,\n",
    "                \"step\": 1,\n",
    "                \"description\": \"Maximum number of tool calling iterations to make in a single researcher step.\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    summarization_model: str = Field(\n",
    "        default = \"openai:gpt-4.1-nano\",\n",
    "        metadata={\n",
    "            \"x_oap_ui_config\": {\n",
    "                \"type\": \"text\",\n",
    "                \"default\": \"openai:gpt-4.1-nano\",\n",
    "                \"description\": \"Model for summarizing research results from Tavily search results\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    summarization_model_max_tokens: int = Field(\n",
    "        default = 8192,\n",
    "        metadata={\n",
    "            \"x_oap_ui_config\": {\n",
    "                \"type\": \"number\",\n",
    "                \"default\": 8192,\n",
    "                \"description\": \"Maximum output tokens for summarization model\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    research_model: str = Field(\n",
    "        default=\"openai:gpt-4.1\",\n",
    "        metadata={\n",
    "            \"x_oap_ui_config\": {\n",
    "                \"type\": \"text\",\n",
    "                \"default\": \"openai:gpt-4.1\",\n",
    "                \"description\": \"Model for conducting research. NOTE: Make sure your Researcher Model supports the selected search API.\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    reseach_model_max_tokens: int = Field(\n",
    "        default = 10000,\n",
    "                metadata={\n",
    "            \"x_oap_ui_config\": {\n",
    "                \"type\": \"number\",\n",
    "                \"default\": 10000,\n",
    "                \"description\": \"Maximum output tokens for research model\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    compression_model: str = Field(\n",
    "        default = \"openai:gpt-4.1-mini\",\n",
    "        metadata={\n",
    "            \"x_oap_ui_config\": {\n",
    "                \"type\": \"text\",\n",
    "                \"default\": \"openai:gpt-4.1-mini\",\n",
    "                \"description\": \"Model for compressing research findings from sub-agents. NOTE: Make sure your Compression Model supports the selected search API.\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    compression_model_max_tokens: int = Field(\n",
    "        default = 8192,\n",
    "        metadata = {\n",
    "            \"x_oap_ui_config\": {\n",
    "                \"type\": \"number\",\n",
    "                \"default\": 8192,\n",
    "                \"description\": \"Maximum output tokens for compression model\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    final_report_model: str = Field(\n",
    "        default=\"openai:gpt-4.1\",\n",
    "        metadata={\n",
    "            \"x_oap_ui_config\": {\n",
    "                \"type\": \"text\",\n",
    "                \"default\": \"openai:gpt-4.1\",\n",
    "                \"description\": \"Model for writing the final report from all research findings\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    final_report_model_max_tokens: int = Field(\n",
    "        default=10000,\n",
    "        metadata={\n",
    "            \"x_oap_ui_config\": {\n",
    "                \"type\": \"number\",\n",
    "                \"default\": 10000,\n",
    "                \"description\": \"Maximum output tokens for final report model\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    mcp_config: Optional[MCPConfig] = Field(\n",
    "        default = None,\n",
    "        optional=True,\n",
    "        metadata={\n",
    "            \"x_oap_ui_config\": {\n",
    "                \"type\": \"mcp\",\n",
    "                \"description\": \"MCP server configuration\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    mcp_prompt: Optional[str] = Field(\n",
    "        default=None,\n",
    "        optional=True,\n",
    "        metadata={\n",
    "            \"x_oap_ui_config\": {\n",
    "                \"type\": \"text\",\n",
    "                \"description\": \"Any additional instructions to pass along to the Agent regarding the MCP tools that are available to it.\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    @classmethod\n",
    "    def from_runnable_config(\n",
    "        cls, config: Optional[RunnableConfig] = None\n",
    "    ) -> \"Configuration\": \n",
    "    \"\"\"Create a Configuration instance from a RunnableConfig.\"\"\"ArithmeticError\n",
    "        configurable = config.get(\"configurable\", {}) if config else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fcee17ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "configuration(max_structured_output_retries=3, allow_clarification=True, max_concurrent_research_units=5, search_api=<SearchAPI.TAVILY: 'tavily'>, max_react_tool_calls=5, summarization_model='openai:gpt-4.1-nano', summarization_model_max_tokens=8192, research_model='openai:gpt-4.1', reseach_model_max_tokens=10000, compression_model='openai:gpt-4.1-mini', compression_model_max_tokens=8192, final_report_model='openai:gpt-4.1', final_report_model_max_tokens=10000, mcp_config=MCPConfig(url='test', tools=False, auth_required=False))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configuration(mcp_config={\"url\":\"test\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
